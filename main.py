import os
import re
import json
import aiohttp
import tomllib
import xml.etree.ElementTree as ET
import urllib.parse
from typing import List, Dict, Any, Tuple, Optional
from loguru import logger

from WechatAPI import WechatAPIClient
from utils.decorators import on_text_message, on_xml_message
from utils.plugin_base import PluginBase


class JDRebate(PluginBase):
    """äº¬ä¸œå•†å“è½¬é“¾è¿”åˆ©æ’ä»¶"""
    description = "äº¬ä¸œå•†å“è½¬é“¾è¿”åˆ©æ’ä»¶ - è‡ªåŠ¨è¯†åˆ«äº¬ä¸œé“¾æ¥å¹¶ç”Ÿæˆå¸¦è¿”åˆ©çš„æ¨å¹¿é“¾æ¥"
    author = "wspzf"
    version = "1.2.0"

    def __init__(self):
        super().__init__()
        # è·å–é…ç½®æ–‡ä»¶è·¯å¾„
        config_path = os.path.join(os.path.dirname(__file__), "config.toml")

        try:
            with open(config_path, "rb") as f:
                config = tomllib.load(f)

            # è¯»å–åŸºæœ¬é…ç½®
            basic_config = config.get("basic", {})
            self.enable = basic_config.get("enable", False)  # æ˜¯å¦å¯ç”¨æ’ä»¶
            self.appkey = basic_config.get("appkey", "")  # æŠ˜äº¬å®¢appkey
            self.union_id = basic_config.get("union_id", "")  # è”ç›ŸID
            self.group_mode = basic_config.get("group_mode", "all")  # æ–°å¢ï¼šç¾¤ç»„æ§åˆ¶æ¨¡å¼ï¼Œé»˜è®¤ä¸º "all"
            self.group_list = basic_config.get("group_list", [])  # æ–°å¢ï¼šç¾¤ç»„/ç”¨æˆ·åˆ—è¡¨
            self.signurl = basic_config.get("signurl", "5")  # signurlå‚æ•°ï¼Œ5è¿”å›æ›´è¯¦ç»†ä¿¡æ¯
            self.chain_type = basic_config.get("chain_type", "2")  # chainTypeå‚æ•°ï¼Œ2è¿”å›çŸ­é“¾æ¥
            self.show_commission = basic_config.get("show_commission", True)  # æ˜¯å¦æ˜¾ç¤ºè¿”åˆ©é‡‘é¢
            
            # ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ï¼Œä½¿ç”¨éæ•è·ç»„ç¡®ä¿è¿”å›å®Œæ•´é“¾æ¥
            self.jd_link_pattern = r"https?://[^\s<>]*(?:3\.cn|jd\.|jingxi|u\.jd\.com)[^\s<>]+"

            # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
            self.jd_link_regex = re.compile(self.jd_link_pattern)
            
            self.api_url = "http://api.zhetaoke.com:20000/api/open_jing_union_open_promotion_byunionid_get.ashx" # ç›´æ¥å†™å…¥ api_url

            logger.success(f"äº¬ä¸œå•†å“è½¬é“¾è¿”åˆ©æ’ä»¶é…ç½®åŠ è½½æˆåŠŸ")
            logger.info(f"ç¾¤ç»„æ§åˆ¶æ¨¡å¼: {self.group_mode}")
            logger.info(f"ç¾¤ç»„/ç”¨æˆ·åˆ—è¡¨: {self.group_list}")
            logger.info(f"äº¬ä¸œé“¾æ¥åŒ¹é…æ¨¡å¼: {self.jd_link_pattern}")
            logger.info(f"æ˜¯å¦æ˜¾ç¤ºè¿”åˆ©é‡‘é¢: {self.show_commission}")
        except Exception as e:
            logger.error(f"åŠ è½½äº¬ä¸œå•†å“è½¬é“¾è¿”åˆ©æ’ä»¶é…ç½®å¤±è´¥: {str(e)}")
            self.enable = False  # é…ç½®åŠ è½½å¤±è´¥ï¼Œç¦ç”¨æ’ä»¶

    @on_text_message(priority=90)  # æé«˜ä¼˜å…ˆçº§ï¼Œç¡®ä¿å…ˆäºå…¶ä»–æ’ä»¶å¤„ç†
    async def handle_text(self, bot: WechatAPIClient, message: dict):
        """å¤„ç†æ–‡æœ¬æ¶ˆæ¯ï¼Œæ£€æµ‹å¹¶è½¬æ¢äº¬ä¸œé“¾æ¥"""
        if not self.enable:
            logger.debug("äº¬ä¸œè½¬é“¾æ’ä»¶æœªå¯ç”¨")
            return True  # æ’ä»¶æœªå¯ç”¨ï¼Œå…è®¸åç»­æ’ä»¶å¤„ç†

        # è·å–æ¶ˆæ¯å†…å®¹
        content = message.get("Content", "")
        from_user = message.get("FromWxid", "")

        logger.debug(f"äº¬ä¸œè½¬é“¾æ’ä»¶æ”¶åˆ°æ–‡æœ¬æ¶ˆæ¯: {content}")

        # æ£€æŸ¥æ¶ˆæ¯æ¥æºæ˜¯å¦åœ¨å…è®¸çš„èŒƒå›´å†…
        if not await self._check_allowed_source(from_user):
            return True
        
        # å¤„ç†æ–‡æœ¬ä¸­çš„äº¬ä¸œé“¾æ¥
        return await self._process_links_in_text(bot, from_user, content)
    
    @on_xml_message(priority=90)  # æ·»åŠ å¯¹XMLæ¶ˆæ¯çš„å¤„ç†
    async def handle_xml(self, bot: WechatAPIClient, message: dict):
        """å¤„ç†XMLæ¶ˆæ¯ï¼Œæå–å¹¶è½¬æ¢äº¬ä¸œé“¾æ¥"""
        if not self.enable:
            logger.debug("äº¬ä¸œè½¬é“¾æ’ä»¶æœªå¯ç”¨")
            return True  # æ’ä»¶æœªå¯ç”¨ï¼Œå…è®¸åç»­æ’ä»¶å¤„ç†
        
        # è·å–æ¶ˆæ¯å†…å®¹
        content = message.get("Content", "")
        from_user = message.get("FromWxid", "")
        
        logger.debug(f"äº¬ä¸œè½¬é“¾æ’ä»¶æ”¶åˆ°XMLæ¶ˆæ¯")
        
        # æ£€æŸ¥æ¶ˆæ¯æ¥æºæ˜¯å¦åœ¨å…è®¸çš„èŒƒå›´å†…
        if not await self._check_allowed_source(from_user):
            return True
        
        try:
            # è§£æXMLå†…å®¹
            root = ET.fromstring(content)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯äº¬ä¸œå•†å“åˆ†äº«
            appmsg = root.find(".//appmsg")
            if appmsg is None:
                logger.debug("éå•†å“åˆ†äº«XMLæ¶ˆæ¯ï¼Œè·³è¿‡å¤„ç†")
                return True
            
            # è·å–æ¶ˆæ¯ç±»å‹
            type_elem = appmsg.find("type")
            msg_type = type_elem.text if type_elem is not None else None
            logger.debug(f"è§£æåˆ°çš„ XML ç±»å‹: {msg_type}")
            
            # æå–å•†å“ä¿¡æ¯çš„æ–¹æ³•ï¼Œæ ¹æ®ä¸åŒç±»å‹é‡‡ç”¨ä¸åŒçš„æå–ç­–ç•¥
            url = None
            sku = None
            
            # æå–URLè·¯å¾„
            url_elem = appmsg.find("url")
            if url_elem is not None:
                url = url_elem.text
            
            # æƒ…å†µ1: å¸¸è§„URLåˆ†äº«
            if url and ("item.jd.com" in url or "item.m.jd.com" in url):
                logger.debug(f"ä»URLä¸­æå–äº¬ä¸œå•†å“é“¾æ¥: {url}")
                # å»é™¤URLä¸­çš„å‚æ•°éƒ¨åˆ†(é—®å·åé¢çš„å†…å®¹)
                url = self._clean_url(url)
                
            # æƒ…å†µ2: äº¬ä¸œå°ç¨‹åºåˆ†äº« (type 33)
            elif msg_type == "33" or msg_type == "36":
                logger.debug(f"æ£€æµ‹åˆ°äº¬ä¸œå°ç¨‹åºåˆ†äº«ï¼Œç±»å‹: {msg_type}")
                # å°è¯•ä»pagepathä¸­æå–SKU
                weappinfo = appmsg.find("weappinfo")
                if weappinfo is not None:
                    pagepath = weappinfo.find("pagepath")
                    if pagepath is not None and pagepath.text:
                        pagepath_text = pagepath.text
                        logger.debug(f"è§£æåˆ°å°ç¨‹åºè·¯å¾„: {pagepath_text}")
                        
                        # æå–SKU
                        sku_match = re.search(r'sku=(\d+)', pagepath_text)
                        if sku_match:
                            sku = sku_match.group(1)
                            logger.debug(f"ä»å°ç¨‹åºè·¯å¾„ä¸­æå–åˆ°SKU: {sku}")
                            # æ„å»ºæ ‡å‡†äº¬ä¸œå•†å“é“¾æ¥
                            url = f"https://item.jd.com/{sku}.html"
                            logger.debug(f"æ„å»ºæ ‡å‡†äº¬ä¸œé“¾æ¥: {url}")
                        else:
                            logger.debug(f"æ— æ³•ä»è·¯å¾„ä¸­æå–SKU: {pagepath_text}")
                    else:
                        logger.debug("æœªæ‰¾åˆ°pagepathå…ƒç´ æˆ–pagepathä¸ºç©º")
                else:
                    logger.debug("æœªæ‰¾åˆ°weappinfoå…ƒç´ ")
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸæå–åˆ°æœ‰æ•ˆäº¬ä¸œé“¾æ¥
            if url and self._is_jd_link(url):
                logger.info(f"ä»XMLæ¶ˆæ¯ä¸­æå–åˆ°äº¬ä¸œå•†å“é“¾æ¥: {url}")
                
                # è½¬æ¢é“¾æ¥
                converted_content = await self.convert_link(url)
                if converted_content:
                    # ç›´æ¥å‘é€è½¬é“¾ç»“æœ
                    await bot.send_text_message(from_user, converted_content)
                    logger.success(f"æˆåŠŸå‘é€XMLè½¬é“¾æ–‡æ¡ˆåˆ° {from_user}")
                    return False  # é˜»æ­¢åç»­æ’ä»¶å¤„ç†
            else:
                logger.debug(f"æœªèƒ½æå–æœ‰æ•ˆçš„äº¬ä¸œé“¾æ¥æˆ–éäº¬ä¸œé“¾æ¥")
                
        except Exception as e:
            logger.error(f"å¤„ç†XMLæ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
            
        return True
        
    async def _check_allowed_source(self, from_user: str) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯æ¥æºæ˜¯å¦åœ¨å…è®¸çš„èŒƒå›´å†…"""
        # æ£€æŸ¥æ¶ˆæ¯æ¥æºæ˜¯å¦ä¸ºç§èŠæˆ–ç¾¤èŠ
        is_group_message = from_user.endswith("@chatroom")
        
        if self.group_mode == "all":
            logger.debug(f"ç¾¤ç»„æ§åˆ¶æ¨¡å¼ä¸º 'all'ï¼Œå…è®¸æ¥è‡ª {from_user} çš„æ¶ˆæ¯")
            return True
        elif self.group_mode == "whitelist":
            if from_user in self.group_list:
                logger.debug(f"ç¾¤ç»„æ§åˆ¶æ¨¡å¼ä¸º 'whitelist'ï¼Œ{from_user} åœ¨ç™½åå•ä¸­ï¼Œå…è®¸å¤„ç†")
                return True
            else:
                logger.debug(f"ç¾¤ç»„æ§åˆ¶æ¨¡å¼ä¸º 'whitelist'ï¼Œ{from_user} ä¸åœ¨ç™½åå•ä¸­ï¼Œä¸å¤„ç†")
                return False
        elif self.group_mode == "blacklist":
            if from_user in self.group_list:
                logger.debug(f"ç¾¤ç»„æ§åˆ¶æ¨¡å¼ä¸º 'blacklist'ï¼Œ{from_user} åœ¨é»‘åå•ä¸­ï¼Œä¸å¤„ç†")
                return False
            else:
                logger.debug(f"ç¾¤ç»„æ§åˆ¶æ¨¡å¼ä¸º 'blacklist'ï¼Œ{from_user} ä¸åœ¨é»‘åå•ä¸­ï¼Œå…è®¸å¤„ç†")
                return True
        else:
            logger.warning(f"æœªçŸ¥çš„ç¾¤ç»„æ§åˆ¶æ¨¡å¼: {self.group_mode}ï¼Œé»˜è®¤å…è®¸æ‰€æœ‰æ¥æº")
            return True
    
    def _is_jd_link(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯äº¬ä¸œé“¾æ¥"""
        return bool(self.jd_link_regex.match(url))
    
    def _clean_url(self, url: str) -> str:
        """æ¸…ç†URLï¼Œå»é™¤å‚æ•°éƒ¨åˆ†"""
        if "?" in url:
            return url.split("?")[0]
        return url
        
    async def _process_links_in_text(self, bot: WechatAPIClient, from_user: str, content: str) -> bool:
        """å¤„ç†æ–‡æœ¬ä¸­çš„äº¬ä¸œé“¾æ¥"""
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„äº¬ä¸œé“¾æ¥
        jd_links = self.jd_link_regex.findall(content)
        
        # å¦ä¸€ç§æ–¹æ³•ï¼šå¦‚æœä¸Šé¢çš„findallä»ç„¶åªè¿”å›éƒ¨åˆ†åŒ¹é…ï¼Œåˆ™ä½¿ç”¨finditer
        if not jd_links or (len(jd_links) == 1 and len(jd_links[0]) < 10):
            logger.debug("ä½¿ç”¨findallå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨finditeråŒ¹é…")
            jd_links = []
            for match in self.jd_link_regex.finditer(content):
                jd_links.append(match.group(0))
                
        logger.debug(f"æ£€æµ‹åˆ°åŸå§‹é“¾æ¥: {jd_links}")
        
        # è¿‡æ»¤æ— æ•ˆé“¾æ¥å¹¶æ¸…ç†URL
        valid_links = []
        for link in jd_links:
            if len(link) > 12 and ('http' in link or 'jd.com' in link or 'u.jd.com' in link):
                # æ¸…ç†URLï¼Œå»é™¤å‚æ•°éƒ¨åˆ†
                clean_link = self._clean_url(link)
                valid_links.append(clean_link)
                # è®°å½•åŸå§‹é“¾æ¥å’Œæ¸…ç†åçš„é“¾æ¥ï¼Œç”¨äºåç»­æ›¿æ¢
                if clean_link != link:
                    logger.debug(f"æ¸…ç†é“¾æ¥: {link} -> {clean_link}")
        
        logger.debug(f"è¿‡æ»¤åçš„æœ‰æ•ˆé“¾æ¥: {valid_links}")
        
        if not valid_links:
            logger.debug("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„äº¬ä¸œé“¾æ¥ï¼Œä¸å¤„ç†")
            return True  # æ²¡æœ‰æ‰¾åˆ°äº¬ä¸œé“¾æ¥ï¼Œå…è®¸åç»­æ’ä»¶å¤„ç†
        
        logger.info(f"æ£€æµ‹åˆ°{len(valid_links)}ä¸ªäº¬ä¸œé“¾æ¥ï¼Œå‡†å¤‡è½¬é“¾")
        
        # å¤„ç†é“¾æ¥
        if len(valid_links) == 1:
            # åªæœ‰ä¸€ä¸ªé“¾æ¥ï¼Œç›´æ¥è¿”å›è½¬é“¾åçš„æ–‡æ¡ˆ
            logger.debug(f"å¤„ç†å•ä¸ªé“¾æ¥: {valid_links[0]}")
            converted_content = await self.convert_link(valid_links[0])
            if converted_content:
                await bot.send_text_message(from_user, converted_content)
                logger.success(f"æˆåŠŸå‘é€è½¬é“¾æ–‡æ¡ˆåˆ° {from_user}")
                return False  # é˜»æ­¢åç»­æ’ä»¶å¤„ç†
        else:
            # æœ‰å¤šä¸ªé“¾æ¥ï¼Œæ›¿æ¢åŸæ¶ˆæ¯ä¸­çš„æ¯ä¸ªé“¾æ¥
            logger.debug(f"å¤„ç†å¤šä¸ªé“¾æ¥: {valid_links}")
            replaced_content = content
            has_conversion = False
            
            # åˆ›å»ºåŸå§‹é“¾æ¥åˆ°æ¸…ç†åé“¾æ¥çš„æ˜ å°„
            link_map = {}
            for link in jd_links:
                clean_link = self._clean_url(link)
                if len(clean_link) > 12 and ('http' in clean_link or 'jd.com' in clean_link or 'u.jd.com' in clean_link):
                    link_map[link] = clean_link
            
            # å¤„ç†æ¯ä¸ªæ¸…ç†åçš„é“¾æ¥
            for original_link, clean_link in link_map.items():
                result = await self.convert_link_official(clean_link)
                logger.debug(f"é“¾æ¥ {clean_link} è½¬æ¢ç»“æœ: {result}")
                if result:
                    # æ›¿æ¢åŸæ¶ˆæ¯ä¸­çš„åŸå§‹é“¾æ¥ä¸ºè½¬é“¾åçš„é“¾æ¥
                    replaced_content = replaced_content.replace(original_link, result)
                    has_conversion = True
            
            if has_conversion:
                await bot.send_text_message(from_user, replaced_content)
                logger.success(f"æˆåŠŸå‘é€å¤šé“¾æ¥è½¬é“¾ç»“æœåˆ° {from_user}")
                return False  # é˜»æ­¢åç»­æ’ä»¶å¤„ç†
                
        return True  # å…è®¸åç»­æ’ä»¶å¤„ç†
    
    async def _parse_api_response(self, api_json_result: dict) -> Optional[Dict[str, Any]]:
        """
        Parses the API JSON response, attempting to handle two known structures.
        Returns a dictionary with extracted data or None if parsing fails or data is invalid.
        """
        try:
            # Attempt to parse Structure 1 (nested, e.g., jd_union_open_promotion_byunionid_get_response)
            if "jd_union_open_promotion_byunionid_get_response" in api_json_result:
                response_data = api_json_result.get("jd_union_open_promotion_byunionid_get_response", {})
                outer_code = response_data.get("code")
                if outer_code == "0": #äº¬ä¸œè”ç›Ÿå¤–å±‚codeï¼Œ0è¡¨ç¤ºæˆåŠŸ
                    result_str = response_data.get("result")
                    if result_str and isinstance(result_str, str):
                        try:
                            inner_result = json.loads(result_str) # 'result' is a JSON string
                            inner_code = inner_result.get("code") # æŠ˜äº¬å®¢å†…å±‚code
                            if inner_code == 200: # 200è¡¨ç¤ºæˆåŠŸ
                                data_payload = inner_result.get("data", {})
                                if data_payload and isinstance(data_payload, dict) :
                                    short_url = data_payload.get("shortURL")
                                    click_url = data_payload.get("clickURL") # clickURL is also in this structure
                                    if short_url:
                                        return {
                                            "shorturl": short_url,
                                            "clickURL": click_url, # Capture clickURL if present
                                            "_is_minimal": True # Indicates less detailed data
                                        }
                                    else:
                                        logger.warning("API (Structure 1) did not return shortURL in data payload.")
                                else:
                                    logger.warning(f"API (Structure 1) 'data' payload is missing or not a dict. Inner result: {inner_result}")
                            else:
                                logger.warning(f"API (Structure 1) inner code: {inner_code}, message: {inner_result.get('message')}. RequestId: {inner_result.get('requestId')}")
                        except json.JSONDecodeError as e:
                            logger.error(f"API (Structure 1) failed to parse inner JSON 'result': {e}. Result string: '{result_str[:200]}...'")
                    else:
                        logger.warning(f"API (Structure 1) 'result' string not found or not a string. Response data: {str(response_data)[:200]}")
                else:
                    logger.warning(f"API (Structure 1) outer_code: {outer_code}. Full response: {str(response_data)[:500]}")
                return None # Failed to process structure 1 correctly or outer_code indicated error

            # Attempt to parse Structure 2 (flat, with "status" and "content")
            elif "status" in api_json_result and api_json_result.get("status") == 200:
                content_items = api_json_result.get("content")
                if content_items and isinstance(content_items, list) and len(content_items) > 0:
                    item = content_items[0]
                    # This structure typically contains full details
                    return {
                        "title": item.get("title", ""),
                        "original_price": item.get("size", ""),
                        "quanhou_jiage": item.get("quanhou_jiage", ""),
                        "coupon_info": item.get("coupon_info", ""),
                        "coupon_amount": item.get("coupon_info_money", ""),
                        "commission": item.get("tkfee3", ""),
                        "shorturl": item.get("shorturl", ""),
                        "coupon_click_url": item.get("coupon_click_url", ""),
                        "item_url": item.get("item_url", ""),
                        "_is_minimal": False
                    }
                else:
                    # Handle cases like {"status":200,"message":"succ","data":null,"cid":"xxxxx"}
                    if api_json_result.get("data") is None and api_json_result.get("message"):
                        logger.warning(f"API (Structure 2 like) 'content' was empty or invalid, message: {api_json_result.get('message')}")
                    else:
                        logger.warning("API (Structure 2) 'content' is empty or not a list.")
            
            # If neither structure matched or a non-200 status for structure 2
            else:
                logger.warning(f"API response did not match known structures or indicated an error. Status: {api_json_result.get('status')}. Raw: {str(api_json_result)[:500]}")

        except Exception as e:
            logger.error(f"Unexpected error during API response parsing: {e}. Raw response: {str(api_json_result)[:500]}")
        
        return None
    
    async def convert_link(self, link: str) -> Optional[str]:
        """ä½¿ç”¨æŠ˜äº¬å®¢APIè½¬æ¢é“¾æ¥ï¼Œè¿”å›è½¬é“¾åçš„å®Œæ•´æ–‡æ¡ˆ"""
        try:
            logger.debug(f"å¼€å§‹è½¬æ¢é“¾æ¥ (convert_link): {link}")
            encoded_link = urllib.parse.quote(link)
            
            async with aiohttp.ClientSession() as session:
                params = {
                    "appkey": self.appkey,
                    "materialId": encoded_link,
                    "unionId": self.union_id,
                    "chainType": self.chain_type,
                    "signurl": self.signurl
                }
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    "Content-Type": "application/x-www-form-urlencoded", # Keep as is, GET uses params in URL
                    "Accept": "application/json"
                }
                logger.debug(f"è¯·æ±‚å‚æ•° (convert_link): {params}")
                async with session.get(self.api_url, params=params, headers=headers) as response:
                    if response.status != 200:
                        logger.error(f"è½¬é“¾APIè¯·æ±‚å¤±è´¥ (convert_link): {response.status}, Response: {await response.text()}")
                        return None
                    try:
                        text = await response.text()
                        api_json_result = json.loads(text) # Parse the JSON text
                        logger.debug(f"APIè¿”å›åŸå§‹ç»“æœ (convert_link): {str(api_json_result)[:1000]}") # Log raw for debug
                    except json.JSONDecodeError as e:
                        logger.error(f"è§£æAPIå“åº”JSONå¤±è´¥ (convert_link): {e}. Response text: {text[:500]}")
                        return None
            
            parsed_data = await self._parse_api_response(api_json_result)

            if not parsed_data:
                logger.warning("convert_link: _parse_api_response returned None.")
                return None

            shorturl = parsed_data.get("shorturl")
            if not shorturl:
                logger.warning("convert_link: Parsed API data does not contain a short URL.")
                return None

            if parsed_data.get("_is_minimal"):
                logger.info(f"API for '{link}' returned minimal data. Sending simplified message with URL: {shorturl}")
                return f"ğŸ“Œ äº¬ä¸œæ¨å¹¿é“¾æ¥\nğŸ‘‰ {shorturl}"

            # Build the rich message using data from parsed_data
            title = parsed_data.get("title", "äº¬ä¸œå•†å“") # Default title if empty
            original_price = parsed_data.get("original_price", "")
            quanhou_jiage = parsed_data.get("quanhou_jiage", "")
            coupon_info = parsed_data.get("coupon_info", "")
            coupon_amount = parsed_data.get("coupon_amount", "")
            commission = parsed_data.get("commission", "")
            
            formatted_content = f"ğŸ“Œ {title or 'äº¬ä¸œå•†å“'}\n" # Ensure title is not empty
            
            if quanhou_jiage: # Primary price to show
                price_info = f"ğŸ’° ä»·æ ¼: Â¥{quanhou_jiage}"
                if original_price and original_price != quanhou_jiage:
                    price_info = f"ğŸ’° åŸä»·: Â¥{original_price} åˆ¸å: Â¥{quanhou_jiage}"
                formatted_content += f"{price_info}\n"
            elif original_price: # Fallback if only original price
                 formatted_content += f"ğŸ’° ä»·æ ¼: Â¥{original_price}\n"

            if coupon_info:
                formatted_content += f"ğŸ ä¼˜æƒ : {coupon_info}\n"
            elif coupon_amount and coupon_amount != "0":
                formatted_content += f"ğŸ ä¼˜æƒ åˆ¸: Â¥{coupon_amount}\n"
            
            if self.show_commission and commission and commission != "0":
                formatted_content += f"ğŸ’¸ è¿”åˆ©: Â¥{commission}\n"
            
            formatted_content += f"ğŸ‘‰ è´­ä¹°é“¾æ¥: {shorturl}"
            
            return formatted_content
            
        except Exception as e:
            logger.error(f"è½¬é“¾è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ (convert_link for {link}): {str(e)}")
            return None
    
    async def convert_link_official(self, link: str) -> Optional[str]:
        """ä½¿ç”¨æŠ˜äº¬å®¢APIè½¬æ¢é“¾æ¥ï¼Œåªè¿”å›çŸ­é“¾æ¥æˆ–æœ€ä¼˜å…ˆçš„å¯ç”¨é“¾æ¥"""
        try:
            logger.debug(f"å¼€å§‹è½¬æ¢é“¾æ¥ (official): {link}")
            encoded_link = urllib.parse.quote(link)
            
            async with aiohttp.ClientSession() as session:
                params = {
                    "appkey": self.appkey,
                    "materialId": encoded_link,
                    "unionId": self.union_id,
                    "chainType": self.chain_type,
                    "signurl": self.signurl
                }
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    "Accept": "application/json"
                }
                logger.debug(f"è¯·æ±‚å‚æ•° (official): {params}")
                async with session.get(self.api_url, params=params, headers=headers) as response:
                    if response.status != 200:
                        logger.error(f"è½¬é“¾APIè¯·æ±‚å¤±è´¥ (official): {response.status}, Response: {await response.text()}")
                        return None
                    try:
                        text = await response.text()
                        api_json_result = json.loads(text)
                        logger.debug(f"APIè¿”å›åŸå§‹ç»“æœ (official): {str(api_json_result)[:1000]}")
                    except json.JSONDecodeError as e:
                        logger.error(f"è§£æAPIå“åº”JSONå¤±è´¥ (official): {e}. Response text: {text[:500]}")
                        return None
                
            parsed_data = await self._parse_api_response(api_json_result)

            if not parsed_data:
                logger.warning("convert_link_official: _parse_api_response returned None.")
                return None

            # Priority: shorturl, then clickURL (from minimal), then coupon_click_url/item_url (from full)
            if parsed_data.get("shorturl"):
                return parsed_data.get("shorturl")
            
            if parsed_data.get("_is_minimal") and parsed_data.get("clickURL"):
                logger.debug("convert_link_official: Using clickURL as fallback for minimal response.")
                return parsed_data.get("clickURL")
            
            if not parsed_data.get("_is_minimal"): # Rich data structure
                if parsed_data.get("coupon_click_url"):
                    logger.debug("convert_link_official: Using coupon_click_url as fallback.")
                    return parsed_data.get("coupon_click_url")
                if parsed_data.get("item_url"):
                    logger.debug("convert_link_official: Using item_url as fallback.")
                    return parsed_data.get("item_url")
            
            logger.warning(f"convert_link_official: Parsed API data for {link} did not contain any usable URL.")
            return None
                
        except Exception as e:
            logger.error(f"è½¬é“¾è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ (official for {link}): {str(e)}")
            return None 